{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f538b2ae",
   "metadata": {},
   "source": [
    "# Описание проекта\n",
    "\n",
    "* **Сфера деятельности**: Интернет-магазин\n",
    "\n",
    "* **Цель**: построить модель поиска токсичных комментариев в разделах с описаниями товаров в новом сервисе.\n",
    "\n",
    "* **Ключевые критерии качества модели**\n",
    "    - Метрика F1 $>=$ 0.75\n",
    "\n",
    "* **Задачи**:\n",
    "    - Загрузка данных\n",
    "    - Подготовка данных к построению моделей\n",
    "    - Обучение моделей\n",
    "    - Выбор наилучшей модели и выводы\n",
    "    \n",
    "\n",
    "## Описание данных:\n",
    "* **`toxic`** — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1941d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import notebook\n",
    "#  import pattern\n",
    "import time\n",
    "import spacy\n",
    "from joblib import dump, load\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# from pattern.en import lemma\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.utils import resample\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import notebook\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37913ad1",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4481fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вывод первых 5 строк из таблицы с данными.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Загрузка файла прошла успешно!!!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    try:\n",
    "        df = pd.read_csv('toxic_comments.csv')\n",
    "    except:\n",
    "        df = pd.read_csv('/datasets/taxi.csv')\n",
    "\n",
    "    print('Вывод первых 5 строк из таблицы с данными.')\n",
    "    display(df.head())\n",
    "    print()\n",
    "    print('Загрузка файла прошла успешно!!!')\n",
    "except:\n",
    "    print('При загрузке данных произошла ошибка. Проверьте наличие файла и/или путь к нему.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c963b2",
   "metadata": {},
   "source": [
    "## Первичный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddc64f3",
   "metadata": {},
   "source": [
    "Изучим данные по типам и наличию пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1231ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3389f14",
   "metadata": {},
   "source": [
    "Проверим структуру целевого признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95e1b32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Баланс классов\n",
      "0    89.83%\n",
      "1    10.17%\n",
      "Name: toxic, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Баланс классов')\n",
    "print((df['toxic'].value_counts()/len(df)).map('{:.2%}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4880ba1",
   "metadata": {},
   "source": [
    "**Краткий вывод**:\n",
    "* Пропуски в данных отсуствуют\n",
    "* Типы данных соответствуют их содержимому\n",
    "* В столбце **`text`** присутсвуют лишние для анализа символы\n",
    "* Текстовые данные необходимо лемматизировать\n",
    "* В данных присутсвут **сильный дисбаланс в классах** (соотношение близко 1:9). Это может негативно сказаться на прогнозной силе моделей обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8b8dc",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b986899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция очистки текстовой информации от сторонних символов\n",
    "def clean(text):\n",
    "    \n",
    "    text = text.lower()    \n",
    "    text = re.sub(r'(?:\\n|\\r)', ' ', text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae010320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation why the edits made under my userna...\n",
       "1         daww he matches this background colour im seem...\n",
       "2         hey man im really not trying to edit war its j...\n",
       "3         more i cant make any real suggestions on impro...\n",
       "4         you sir are my hero any chance you remember wh...\n",
       "                                ...                        \n",
       "159566    and for the second time of asking when your vi...\n",
       "159567    you should be ashamed of yourself   that is a ...\n",
       "159568    spitzer   umm theres no actual article for pro...\n",
       "159569    and it looks like it was actually you who put ...\n",
       "159570    and  i really dont think you understand  i cam...\n",
       "Name: clean_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df['text'].apply(clean)\n",
    "df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6589e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Функция лемматизации\n",
    "# def lemmatize(text):\n",
    "#     word_list = text.split()\n",
    "#     return \" \".join([lemma(word) for word in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1efb7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install spacy\n",
    "# # Download spaCy's  'en' Model\n",
    "# !{sys.executable} -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "377cc63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stripe bat hang foot good'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Новая функция лемматизации\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize(text):\n",
    "    temp = []\n",
    "    for token in nlp(text):\n",
    "        if token.is_stop == False:\n",
    "            temp.append(token.lemma_)\n",
    "    return \" \".join(temp)\n",
    "\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "lemmatize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a975f71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>explanation edit username hardcore metallica f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>daww match background colour m seemingly stuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>hey man m try edit war guy constantly remove r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i cant make any real suggestions on impro...</td>\n",
       "      <td>not real suggestion improvement   wonder secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>sir hero chance remember page s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  explanation why the edits made under my userna...   \n",
       "1  daww he matches this background colour im seem...   \n",
       "2  hey man im really not trying to edit war its j...   \n",
       "3  more i cant make any real suggestions on impro...   \n",
       "4  you sir are my hero any chance you remember wh...   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation edit username hardcore metallica f...  \n",
       "1  daww match background colour m seemingly stuck...  \n",
       "2  hey man m try edit war guy constantly remove r...  \n",
       "3  not real suggestion improvement   wonder secti...  \n",
       "4                    sir hero chance remember page s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    df['lemm_text'] = df['clean_text'].apply(lemmatize)\n",
    "    display(df.head())\n",
    "except Exception as error:\n",
    "    print('Возникла ошибка!!!')\n",
    "    print()\n",
    "    print('ОШИБКА:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d478c1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Возникла ошибка!!!\n",
      "\n",
      "ОШИБКА: [Errno 2] No such file or directory: '/datasets/toxic_comments_ppg.csv'\n",
      "Сохраню в свою дирректорию\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>explanation edit username hardcore metallica f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>daww match background colour m seemingly stuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>hey man m try edit war guy constantly remove r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i cant make any real suggestions on impro...</td>\n",
       "      <td>not real suggestion improvement   wonder secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>sir hero chance remember page s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  explanation why the edits made under my userna...   \n",
       "1  daww he matches this background colour im seem...   \n",
       "2  hey man im really not trying to edit war its j...   \n",
       "3  more i cant make any real suggestions on impro...   \n",
       "4  you sir are my hero any chance you remember wh...   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation edit username hardcore metallica f...  \n",
       "1  daww match background colour m seemingly stuck...  \n",
       "2  hey man m try edit war guy constantly remove r...  \n",
       "3  not real suggestion improvement   wonder secti...  \n",
       "4                    sir hero chance remember page s  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    dump(df, '/datasets/toxic_comments_lemm.csv')\n",
    "    df = load('/datasets/toxic_comments_lemm.csv')\n",
    "except Exception as error:\n",
    "    print('Возникла ошибка!!!')\n",
    "    print()\n",
    "    print('ОШИБКА:', error)\n",
    "    print('Сохраню в свою дирректорию')\n",
    "    dump(df, 'toxic_comments_lemm.csv')\n",
    "    df = load('toxic_comments_lemm.csv')\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0678be9",
   "metadata": {},
   "source": [
    "<font color='purple'><b>ИСПРАВЛЕНИЕ ЛЕММАТИЗАЦИИ. Решил сохранить себе файл ,чтобы можно было его не потерять и начинать с этого момента.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6faffb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load('toxic_comments_lemm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3579687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция балансировки классов путем увеличения выборки\n",
    "rnd_st = 12345\n",
    "def upsample(df):\n",
    "    toxic_comments = df[df['toxic']==1]\n",
    "    non_toxic = df[df['toxic']==0]\n",
    "    toxic_comments_upsample = resample(toxic_comments,\n",
    "                                       replace=True,\n",
    "                                       n_samples=len(non_toxic),\n",
    "                                       random_state=rnd_st)\n",
    "    \n",
    "    df_upsampled = pd.concat([non_toxic, toxic_comments_upsample])\n",
    "\n",
    "    return df_upsampled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f40fdea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры сбалансированного набора данных обучающей выборки (215080, 4)\n",
      "\n",
      "Баланс классов\n",
      "0    50.00%\n",
      "1    50.00%\n",
      "Name: toxic, dtype: object\n",
      "Размеры сбалансированного набора данных тестовой выборки (39893, 4)\n",
      "\n",
      "Баланс классов\n",
      "0    89.76%\n",
      "1    10.24%\n",
      "Name: toxic, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size = 0.25, random_state=rnd_st)\n",
    "\n",
    "df_train_upsample = upsample(df_train)\n",
    "\n",
    "print('Размеры сбалансированного набора данных обучающей выборки', df_train_upsample.shape)\n",
    "print()\n",
    "print('Баланс классов')\n",
    "print((df_train_upsample['toxic'].value_counts()/len(df_train_upsample)).map('{:.2%}'.format))\n",
    "\n",
    "print('Размеры сбалансированного набора данных тестовой выборки', df_test.shape)\n",
    "print()\n",
    "print('Баланс классов')\n",
    "print((df_test['toxic'].value_counts()/len(df_test)).map('{:.2%}'.format))\n",
    "\n",
    "x_train = df_train_upsample['lemm_text']\n",
    "y_train = df_train_upsample['toxic']\n",
    "\n",
    "x_test = df_test['lemm_text']\n",
    "y_test = df_test['toxic']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262bbc2e",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab047ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_st=12345\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=rnd_st)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "estimators = {\n",
    "    'log_reg': LogisticRegression(random_state=rnd_st),\n",
    "    'dec_tree_class': DecisionTreeClassifier(random_state = rnd_st),\n",
    "    'rand_forest_class': RandomForestClassifier(random_state = rnd_st),\n",
    "    'lgmb_class': LGBMClassifier(boosting_type='gbdt', random_state = rnd_st),\n",
    "    'cat_boost_class': CatBoostClassifier(silent=True, random_state = rnd_st)\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'log_reg': {\n",
    "        'max_iter': [150], \n",
    "        'solver': ['liblinear']\n",
    "    },\n",
    "    'dec_tree_class': {\n",
    "        'max_depth': [10, 20, 50]\n",
    "    },\n",
    "    'rand_forest_class': {\n",
    "        'max_depth': [10, 20, 50],\n",
    "        'n_estimators': [5, 10, 20]\n",
    "        \n",
    "    },\n",
    "    'lgmb_class': {\n",
    "        'n_estimators': [10, 20],\n",
    "        'num_leaves': [10, 20],\n",
    "    },\n",
    "    'cat_boost_class': {\n",
    "        'n_estimators': [10, 20, 50]        \n",
    "    }\n",
    "}\n",
    "\n",
    "# vectorizers = {\n",
    "#     'count_vect': CountVectorizer(stop_words=stop_words, dtype=np.float64),\n",
    "#     'tf_idf': TfidfVectorizer(stop_words=stop_words, dtype=np.float64)\n",
    "# }\n",
    "\n",
    "\n",
    "# pipes_list = []\n",
    "# pipes_params_list =[]\n",
    "\n",
    "\n",
    "\n",
    "# pipe = Pipeline([\n",
    "#     ('vectorizer', TfidfVectorizer(ngram_range=(1, 1))),\n",
    "#     ('model', LogisticRegression(max_iter=150, solver='liblinear', random_state=42))\n",
    "# ])\n",
    "\n",
    "# params = {\n",
    "#     'vectorizer__ngram_range': [(1, 1), (3, 1), (5, 2)],\n",
    "#     'model': [LogisticRegression(max_iter=150, solver='liblinear', random_state=42)],\n",
    "#     'model__C': [1, 5, 10, 25],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2a244f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vectorizers.keys())\n",
    "# for vectorizer in vectorizers.keys():\n",
    "#     for estimator in estimators.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ec759",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b824329",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = x_train.values\n",
    "corpus_test = x_test.values\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "count_vect = CountVectorizer(stop_words=stop_words, dtype = np.float64)\n",
    "\n",
    "count_vect_train = count_vect.fit_transform(corpus_train)\n",
    "count_vect_test = count_vect.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b2ab242",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "МОДЕЛЬ LOG_REG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время перебора моделей: 82.92\n",
      "Лучшие параметры модели: LOG_REG: {'max_iter': 150, 'solver': 'liblinear'}\n",
      "f1_score равен: 0.9636853538696775\n",
      "____________________________________________________________________________________________________\n",
      "МОДЕЛЬ DEC_TREE_CLASS\n",
      "Время перебора моделей: 140.34\n",
      "Лучшие параметры модели: DEC_TREE_CLASS: {'max_depth': 50}\n",
      "f1_score равен: 0.8533401694019661\n",
      "____________________________________________________________________________________________________\n",
      "МОДЕЛЬ RAND_FOREST_CLASS\n",
      "Время перебора моделей: 111.89\n",
      "Лучшие параметры модели: RAND_FOREST_CLASS: {'max_depth': 50, 'n_estimators': 20}\n",
      "f1_score равен: 0.8696054888507719\n",
      "____________________________________________________________________________________________________\n",
      "МОДЕЛЬ LGMB_CLASS\n",
      "Время перебора моделей: 111.42\n",
      "Лучшие параметры модели: LGMB_CLASS: {'n_estimators': 20, 'num_leaves': 20}\n",
      "f1_score равен: 0.7805290280531789\n",
      "____________________________________________________________________________________________________\n",
      "МОДЕЛЬ CAT_BOOST_CLASS\n",
      "Время перебора моделей: 418.64\n",
      "Лучшие параметры модели: CAT_BOOST_CLASS: {'n_estimators': 50}\n",
      "f1_score равен: 0.8861030772359942\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "count_vect_best_models = []\n",
    "for model in list(estimators.keys()):\n",
    "    try:\n",
    "        print('МОДЕЛЬ', model.upper())\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        grid = GridSearchCV(estimator=estimators[model], param_grid=params[model], cv=cv, scoring='f1', n_jobs=-1)\n",
    "        grid = grid.fit(count_vect_train, y_train)\n",
    "\n",
    "        best_model = grid.best_estimator_\n",
    "        predictions = best_model.predict(count_vect_train)\n",
    "\n",
    "        print(f'Время перебора моделей: {(time.time()-start):0.2f}')\n",
    "        print(f'Лучшие параметры модели: {model.upper()}: {grid.best_params_}')\n",
    "        print(f'f1_score равен: {f1_score(y_train, predictions)}')\n",
    "        print('_'*100)\n",
    "\n",
    "        count_vect_best_models.append(grid.best_estimator_)\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Возникла ошибка!!! В модели', model.upper())\n",
    "        print()\n",
    "        print('ОШИБКА:', error)\n",
    "        print('НУЖНА ПОМОЩЬ!!!')\n",
    "        print('_'*100)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55a1d7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogisticRegression(max_iter=150, random_state=12345, solver='liblinear'), DecisionTreeClassifier(max_depth=50, random_state=12345), RandomForestClassifier(max_depth=50, n_estimators=20, random_state=12345), LGBMClassifier(n_estimators=20, num_leaves=20, random_state=12345), <catboost.core.CatBoostClassifier object at 0x000002B683D2A610>]\n",
      "\n",
      "f1_score модели LogisticRegression(max_iter=150, random_state=12345, solver='liblinear') равно 0.751398179624959\n",
      "\n",
      "f1_score модели DecisionTreeClassifier(max_depth=50, random_state=12345) равно 0.6662587198629298\n",
      "\n",
      "f1_score модели RandomForestClassifier(max_depth=50, n_estimators=20, random_state=12345) равно 0.4187317321133562\n",
      "\n",
      "f1_score модели LGBMClassifier(n_estimators=20, num_leaves=20, random_state=12345) равно 0.6819824470831183\n",
      "\n",
      "f1_score модели <catboost.core.CatBoostClassifier object at 0x000002B683D2A610> равно 0.7225363041791376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(count_vect_best_models)\n",
    "print()\n",
    "for model in count_vect_best_models:\n",
    "    print(f'f1_score модели {model} равно {f1_score(model.predict(count_vect_test), y_test)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa6a316",
   "metadata": {},
   "source": [
    "**Краткий вывод**\n",
    "* После перебора моделей на основе признаков, сформированных по принципу **\"мешка слов\"** (CountVectorizer), наилучший результат и на обучающей и на тестовой выборках по метрике **f1** показала модель **логистической регрессии**. \n",
    "    - f1_score на обучающей выборке: **0.964** >0.75\n",
    "    - f1_score на тестовой выборке: **0.751** > 0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59ae911",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b84452c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = x_train.values\n",
    "corpus_test = x_test.values\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tf_idf = TfidfVectorizer(stop_words=stop_words, dtype = np.float64)\n",
    "\n",
    "tf_idf_train = tf_idf.fit_transform(corpus_train)\n",
    "tf_idf_test = tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df78b2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "МОДЕЛЬ LOG_REG\n",
      "Время перебора моделей: 10.90\n",
      "Лучшие параметры модели: LOG_REG: {'max_iter': 150, 'solver': 'liblinear'}\n",
      "f1_score равен: 0.9735658172772376\n",
      "____________________________________________________________________________________________________\n",
      "МОДЕЛЬ DEC_TREE_CLASS\n",
      "Время перебора моделей: 148.43\n",
      "Лучшие параметры модели: DEC_TREE_CLASS: {'max_depth': 50}\n",
      "f1_score равен: 0.8605699657811561\n",
      "____________________________________________________________________________________________________\n",
      "МОДЕЛЬ RAND_FOREST_CLASS\n",
      "Время перебора моделей: 120.11\n",
      "Лучшие параметры модели: RAND_FOREST_CLASS: {'max_depth': 50, 'n_estimators': 20}\n",
      "f1_score равен: 0.8851164491086213\n",
      "____________________________________________________________________________________________________\n",
      "МОДЕЛЬ LGMB_CLASS\n",
      "Время перебора моделей: 136.03\n",
      "Лучшие параметры модели: LGMB_CLASS: {'n_estimators': 20, 'num_leaves': 20}\n",
      "f1_score равен: 0.7898731692421781\n",
      "____________________________________________________________________________________________________\n",
      "МОДЕЛЬ CAT_BOOST_CLASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [      nan       nan 0.8895855]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время перебора моделей: 1213.25\n",
      "Лучшие параметры модели: CAT_BOOST_CLASS: {'n_estimators': 50}\n",
      "f1_score равен: 0.8936636075371953\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf_idf_best_models = []\n",
    "for model in list(estimators.keys()):\n",
    "    try:\n",
    "        print('МОДЕЛЬ', model.upper())\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        grid = GridSearchCV(estimator=estimators[model], param_grid=params[model], cv=cv, scoring='f1', n_jobs=-1)\n",
    "        grid = grid.fit(tf_idf_train, y_train)\n",
    "\n",
    "        best_model = grid.best_estimator_\n",
    "        predictions = best_model.predict(tf_idf_train)\n",
    "\n",
    "        print(f'Время перебора моделей: {(time.time()-start):0.2f}')\n",
    "        print(f'Лучшие параметры модели: {model.upper()}: {grid.best_params_}')\n",
    "        print(f'f1_score равен: {f1_score(y_train, predictions)}')\n",
    "        print('_'*100)\n",
    "\n",
    "        tf_idf_best_models.append(grid.best_estimator_)\n",
    "    \n",
    "    except Exception as error:\n",
    "        \n",
    "        print('Возникла ошибка!!! В модели', model.upper())\n",
    "        print()\n",
    "        print('ОШИБКА:', error)\n",
    "        print('НУЖНА ПОМОЩЬ!!!')\n",
    "        print('_'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61b2fc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogisticRegression(max_iter=150, random_state=12345, solver='liblinear'), DecisionTreeClassifier(max_depth=50, random_state=12345), RandomForestClassifier(max_depth=50, n_estimators=20, random_state=12345), LGBMClassifier(n_estimators=20, num_leaves=20, random_state=12345), <catboost.core.CatBoostClassifier object at 0x000002B682959F10>]\n",
      "\n",
      "f1_score модели LogisticRegression(max_iter=150, random_state=12345, solver='liblinear') равно 0.7550818591363587\n",
      "\n",
      "f1_score модели DecisionTreeClassifier(max_depth=50, random_state=12345) равно 0.6607341490545049\n",
      "\n",
      "f1_score модели RandomForestClassifier(max_depth=50, n_estimators=20, random_state=12345) равно 0.4365691489361702\n",
      "\n",
      "f1_score модели LGBMClassifier(n_estimators=20, num_leaves=20, random_state=12345) равно 0.6765036888833312\n",
      "\n",
      "f1_score модели <catboost.core.CatBoostClassifier object at 0x000002B682959F10> равно 0.7212034698583507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_best_models)\n",
    "print()\n",
    "for model in tf_idf_best_models:\n",
    "    print(f'f1_score модели {model} равно {f1_score(model.predict(tf_idf_test), y_test)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb496f7",
   "metadata": {},
   "source": [
    "**Краткий вывод**\n",
    "* После перебора моделей на основе признаков, сформированных по принципу **\"TF-IDF\"** (TfidfVectorizer), наилучший результат и на обучающей и на тестовой выборках по метрике **f1** показала модель **логистической регрессии**. \n",
    "    - f1_score на обучающей выборке: **0.974** >0.75\n",
    "    - f1_score на тестовой выборке: **0.755** > 0.75\n",
    "* Удалось построить и перебрать модели всех классов.\n",
    "    - Однако перебо моделей класса **CatBoostClassifier** осуществлялся весьма долго (**примерно 27 мин**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a2946",
   "metadata": {},
   "source": [
    "## ОБЩИЙ ВЫВОД\n",
    "* На основе полученных данных о содержании и токсичности комментариев были построены несколько классов моделей классификации комментариев по их \"токсичности\" **(логистическая регрессия, дерево решений, случайны лес, LGBMClassifier, CatBoostClassifier)**. В рамках перебора моделей использовались два принципа формирования прзнаков из текстовых данных **(\"мешок слов\" и TF-IDF)**.\n",
    "* Все модели оценивались с учетом значительного дисбаланса классов путем увеличения выборки (upsample метод).\n",
    "* В ходе процесса лемматизации возникла ошибка.\n",
    "    - ОШИБКА: \"generator raised StopIteration\"\n",
    "    - Причина ошибки не утановлена\n",
    "    - **Повторный запуск кода решил данную проблему** (поэтому лемматизация проведена в структуре `try ... except`\n",
    "* Пришлось изменить способ лемматизации из-за ограничений JupyterHub. Время работы кода было увеличено.\n",
    "* Не удалось построить модель **LGBMClassifier** на основе признаков, сформированных по принципу **\"мешка слов\"**:\n",
    "    - ОШИБКА: \"Expected np.float32 or np.float64, met type(int64)\"\n",
    "    - Причина ошибки была устранена (добавили параметр dtupe=np.float64 в функции векторизации)\n",
    "* На основе полученных результатов оценивания моделии и тестирования **наилучшей оказалась модель логистической регрессии на основе признаков, свормированных по принципу TF-IDF**.\n",
    "    - f1_score на обучающей выборке: **0.974** >0.75\n",
    "    - f1_score на тестовой выборке: **0.755** > 0.75"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2392,
    "start_time": "2022-08-05T17:52:14.131Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-05T17:52:16.526Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-05T17:52:16.527Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-05T17:52:16.529Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-05T17:52:16.530Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-05T17:52:16.531Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-05T17:52:16.532Z"
   },
   {
    "duration": 0,
    "start_time": "2022-08-05T17:52:16.533Z"
   },
   {
    "duration": 18987,
    "start_time": "2022-08-05T17:55:12.703Z"
   },
   {
    "duration": 38,
    "start_time": "2022-08-05T17:55:31.693Z"
   },
   {
    "duration": 12535,
    "start_time": "2022-08-05T17:58:51.584Z"
   },
   {
    "duration": 636,
    "start_time": "2022-08-05T18:02:53.118Z"
   },
   {
    "duration": 9617,
    "start_time": "2022-08-05T18:03:07.726Z"
   },
   {
    "duration": 955,
    "start_time": "2022-08-05T18:04:06.744Z"
   },
   {
    "duration": 936,
    "start_time": "2022-08-05T18:04:21.831Z"
   },
   {
    "duration": 1484,
    "start_time": "2022-08-05T18:04:37.159Z"
   },
   {
    "duration": 602,
    "start_time": "2022-08-05T18:05:15.034Z"
   },
   {
    "duration": 11783,
    "start_time": "2022-08-05T18:05:23.400Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
